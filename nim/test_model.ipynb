{
	"cells": [
		{
			"cell_type": "markdown",
			"id": "5ddd6b9e-6c0a-405d-8e7a-0ca7c781a20b",
			"metadata": {
				"tags": []
			},
			"source": [
				"# Connect with the NIM model\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "ae4684dc-b550-47f7-a053-abbbf1799e84",
			"metadata": {
				"tags": []
			},
			"outputs": [],
			"source": [
				"pip install openai"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "30d5023e-df32-4a69-863e-4e469e0f93bc",
			"metadata": {
				"tags": []
			},
			"outputs": [],
			"source": [
				"from openai import OpenAI\n",
				"import httpx\n",
				"\n",
				"client = OpenAI(\n",
				"  base_url = \"https://a.nim2.svc.cluster.local/v1\",\n",
				"  api_key = \"sa\",\n",
				"  http_client = httpx.Client(verify=False)\n",
				")\n",
				"\n",
				"\n",
				"def ask_question(question):\n",
				"    completion = client.chat.completions.create(\n",
				"      model=\"meta/llama3-8b-instruct\",\n",
				"      messages=[{\"role\": \"user\", \"content\": question}],\n",
				"      temperature=0.5,\n",
				"      top_p=1,\n",
				"      max_tokens=1024,\n",
				"      stream=True\n",
				"    )\n",
				"\n",
				"    for chunk in completion:\n",
				"        if chunk.choices[0].delta.content is not None:\n",
				"            print(chunk.choices[0].delta.content, end=\"\")\n",
				"\n",
				"\n",
				"while (True):\n",
				"    question = input(\"#:\")\n",
				"    ask_question(question)"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Python 3.9",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.9.18"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 5
}
